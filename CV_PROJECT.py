# -*- coding: utf-8 -*-
"""Untitled10.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1K2MZILvA5mRu_CGaUXFch7gglXoqdxI8
"""

import tensorflow as tf

# Check for available GPUs
if tf.config.list_physical_devices('GPU'):
    print("GPU is available")
else:
    print("GPU is not available, running on CPU")



import torch
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print("Using device:", device)

!pip install tensorflow
!pip install scikit-image
!pip install opencv-python

from tensorflow.keras.preprocessing.image import img_to_array, load_img
from sklearn.model_selection import train_test_split
import os

import os
import cv2
import numpy as np
import tensorflow as tf
from tensorflow.keras import layers, models
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.preprocessing.image import img_to_array, load_img
from skimage.metrics import structural_similarity as ssim
from skimage.metrics import peak_signal_noise_ratio as psnr
from matplotlib import pyplot as plt
from sklearn.model_selection import train_test_split

# ... [Your existing code for building models] ...

def build_generator():
    model = tf.keras.Sequential([
        layers.Dense(256 * 8 * 8, activation='relu', input_dim=100),
        layers.Reshape((8, 8, 256)),
        layers.Conv2DTranspose(128, kernel_size=3, strides=2, padding='same', activation='relu'),
        layers.Conv2DTranspose(64, kernel_size=3, strides=2, padding='same', activation='relu'),
        layers.Conv2DTranspose(32, kernel_size=3, strides=2, padding='same', activation='relu'),
        layers.Conv2DTranspose(16, kernel_size=3, strides=2, padding='same', activation='relu'),
        layers.Conv2DTranspose(3, kernel_size=3, strides=2, padding='same', activation='tanh')
    ])
    return model

# Discriminator
def build_discriminator():
    model = tf.keras.Sequential([
        layers.Conv2D(64, kernel_size=3, strides=2, padding='same', input_shape=(256, 256, 3), activation='relu'),
        layers.Conv2D(128, kernel_size=3, strides=2, padding='same', activation='relu'),
        layers.Flatten(),
        layers.Dense(1, activation='sigmoid')
    ])
    return model

# GAN
def build_gan(generator, discriminator):
    discriminator.compile(optimizer=Adam(0.0002, 0.5), loss='binary_crossentropy', metrics=['accuracy'])
    discriminator.trainable = False
    gan_input = layers.Input(shape=(100,))
    img = generator(gan_input)
    validity = discriminator(img)
    gan = models.Model(gan_input, validity)
    gan.compile(optimizer=Adam(0.0002, 0.5), loss='binary_crossentropy')
    return gan

#Preprocess images
def preprocess_images(underwater_img, reference_img):
    # Ensure images are correctly converted to NumPy arrays
    if isinstance(underwater_img, str):
        underwater_img = img_to_array(load_img(underwater_img))
    if isinstance(reference_img, str):
        reference_img = img_to_array(load_img(reference_img))

    underwater_img = cv2.resize(underwater_img, (256, 256))
    reference_img = cv2.resize(reference_img, (256, 256))
    underwater_img = (underwater_img.astype(np.float32) - 127.5) / 127.5
    reference_img = (reference_img.astype(np.float32) - 127.5) / 127.5
    return underwater_img, reference_img

# Train GAN
def train_gan(generator, discriminator, gan, images, epochs, batch_size):
    valid = np.ones((batch_size, 1))
    fake = np.zeros((batch_size, 1))
    for epoch in range(epochs):
        idx = np.random.randint(0, images.shape[0], batch_size)
        real_imgs = images[idx]
        real_imgs = tf.image.random_brightness(real_imgs, max_delta=0.1)
        real_imgs = tf.image.random_contrast(real_imgs, lower=0.9, upper=1.1)
        noise = np.random.normal(0, 1, (batch_size, 100))
        gen_imgs = generator.predict(noise)
        d_loss_real = discriminator.train_on_batch(real_imgs, valid)
        d_loss_fake = discriminator.train_on_batch(gen_imgs, fake)
        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)
        noise = np.random.normal(0, 1, (batch_size, 100))
        g_loss = gan.train_on_batch(noise, valid)
        print(f"Epoch {epoch+1}/{epochs} - D loss: {d_loss[0]} - G loss: {g_loss}")

def build_color_correction_subnetwork(input_tensor):
    # This is a simple example; you might need a more complex architecture
    x = layers.Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same')(input_tensor)
    x = layers.Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same')(x)
    x = layers.Conv2D(3, kernel_size=(3, 3), activation='sigmoid', padding='same')(x)
    return x

def build_cnn_model():
    input_img = layers.Input(shape=(256, 256, 3))
    # Feature extraction as before
    x = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(input_img)
    x = layers.MaxPooling2D((2, 2), padding='same')(x)
    x = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)
    x = layers.UpSampling2D((2, 2))(x)
    features_decoded = layers.Conv2D(3, (3, 3), activation='sigmoid', padding='same')(x)

    # Color correction subnetwork
    color_corrected = build_color_correction_subnetwork(features_decoded)

    # Merging feature extraction with color correction
    combined = layers.multiply([features_decoded, color_corrected])

    # Final touch-ups if necessary
    # This could also be a place to apply histogram matching or other techniques
    final_output = layers.Conv2D(3, (1, 1), activation='sigmoid', padding='same')(combined)

    cnn_model = models.Model(inputs=input_img, outputs=final_output)
    cnn_model.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])
    return cnn_model


# Train CNN Model
def train_model(model, underwater_imgs, reference_imgs):
    # Check the shape of the images. They should be 4-dimensional.
    if underwater_imgs.ndim != 4 or reference_imgs.ndim != 4:
        raise ValueError("Input data should be 4-dimensional")

    # Now train the model with the image arrays
    model.fit(underwater_imgs, reference_imgs, epochs=100, batch_size=1)


# Evaluate model
def evaluate_model(model, underwater_img, reference_img):
    predicted_img = model.predict(np.expand_dims(underwater_img, axis=0))[0]
    predicted_img = np.clip(predicted_img, 0, 1)
    psnr_value = psnr(reference_img, predicted_img, data_range=1)
    ssim_value = ssim(reference_img, predicted_img, multichannel=True)
    return psnr_value, ssim_value

# Display image
def display_image(image, title="Image"):
    plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))
    plt.title(title)
    plt.axis('off')
    plt.show()

# # Function to preprocess input data for GAN and CNN
# def preprocess_images(image):
#     image = cv2.resize(image, (256, 256))
#     image = image.astype(np.float32) / 255.0
#     return image

def load_dataset(underwater_dir, ground_truth_dir):
    underwater_images = []
    ground_truth_images = []

    for filename in os.listdir(underwater_dir):
        if filename.endswith(".jpg"):
            uw_img_path = os.path.join(underwater_dir, filename)
            gt_img_path = os.path.join(ground_truth_dir, filename)

            uw_img = img_to_array(load_img(uw_img_path))
            gt_img = img_to_array(load_img(gt_img_path))

            # Pass both uw_img and gt_img to preprocess_images
            uw_img, gt_img = preprocess_images(uw_img, gt_img)

            underwater_images.append(uw_img)
            ground_truth_images.append(gt_img)

    return np.array(underwater_images), np.array(ground_truth_images)



def preprocess_test_image(image_path):
    image = load_img(image_path, target_size=(256, 256))
    image = img_to_array(image)
    image = image.astype(np.float32) / 255.0  # Normalize the image
    image = np.expand_dims(image, axis=0)  # Add the batch dimension
    return image





# ... [Rest of your code including the training functions] ...

def main():
    # Load and preprocess dataset
    underwater_dir = '/content/drive/MyDrive/A'
    ground_truth_dir = '/content/drive/MyDrive/GTr_A'
    underwater_images, ground_truth_images = load_dataset(underwater_dir, ground_truth_dir)

    # Build and compile GAN
    generator = build_generator()
    discriminator = build_discriminator()
    gan = build_gan(generator, discriminator)

    # Train the GAN
    train_gan(generator, discriminator, gan, underwater_images, epochs=15, batch_size=1)

    # Build and compile CNN model
    cnn_model = build_cnn_model()

    # Split into training and validation sets if needed
    uw_train, uw_val, gt_train, gt_val = train_test_split(underwater_images, ground_truth_images, test_size=0.1)

    # Train the CNN model
    train_model(cnn_model, uw_train, gt_train)

    test_underwater_image_path = '/content/12422.png'
    test_underwater_img = preprocess_test_image(test_underwater_image_path)

    # Predict and display the result
    predicted_img = cnn_model.predict(test_underwater_img)[0]
    display_image(predicted_img, "Enhanced Test Image")

if __name__ == "__main__":
    main()

import os
import cv2
import numpy as np
import tensorflow as tf
from tensorflow.keras import layers, models
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.preprocessing.image import img_to_array, load_img
from skimage.metrics import structural_similarity as ssim
from skimage.metrics import peak_signal_noise_ratio as psnr
from matplotlib import pyplot as plt
from sklearn.model_selection import train_test_split

# ... [Your existing code for building models] ...

def build_generator():
    model = tf.keras.Sequential([
        layers.Dense(256 * 8 * 8, activation='relu', input_dim=100),
        layers.Reshape((8, 8, 256)),
        layers.Conv2DTranspose(128, kernel_size=3, strides=2, padding='same', activation='relu'),
        layers.Conv2DTranspose(64, kernel_size=3, strides=2, padding='same', activation='relu'),
        layers.Conv2DTranspose(32, kernel_size=3, strides=2, padding='same', activation='relu'),
        layers.Conv2DTranspose(16, kernel_size=3, strides=2, padding='same', activation='relu'),
        layers.Conv2DTranspose(3, kernel_size=3, strides=2, padding='same', activation='tanh')
    ])
    return model

# Discriminator
def build_discriminator():
    model = tf.keras.Sequential([
        layers.Conv2D(64, kernel_size=3, strides=2, padding='same', input_shape=(256, 256, 3), activation='relu'),
        layers.Conv2D(128, kernel_size=3, strides=2, padding='same', activation='relu'),
        layers.Flatten(),
        layers.Dense(1, activation='sigmoid')
    ])
    return model

# GAN
def build_gan(generator, discriminator):
    discriminator.compile(optimizer=Adam(0.0002, 0.5), loss='binary_crossentropy', metrics=['accuracy'])
    discriminator.trainable = False
    gan_input = layers.Input(shape=(100,))
    img = generator(gan_input)
    validity = discriminator(img)
    gan = models.Model(gan_input, validity)
    gan.compile(optimizer=Adam(0.0002, 0.5), loss='binary_crossentropy')
    return gan

#Preprocess images
def preprocess_images(underwater_img, reference_img):
    underwater_img = cv2.resize(underwater_img, (256, 256))
    reference_img = cv2.resize(reference_img, (256, 256))
    underwater_img = underwater_img.astype(np.float32) / 255.0
    reference_img = reference_img.astype(np.float32) / 255.0
    return underwater_img, reference_img

# Train GAN
def train_gan(generator, discriminator, gan, images, epochs, batch_size):
    valid = np.ones((batch_size, 1))
    fake = np.zeros((batch_size, 1))
    for epoch in range(epochs):
        idx = np.random.randint(0, images.shape[0], batch_size)
        real_imgs = images[idx]
        real_imgs = tf.image.random_brightness(real_imgs, max_delta=0.1)
        real_imgs = tf.image.random_contrast(real_imgs, lower=0.9, upper=1.1)
        noise = np.random.normal(0, 1, (batch_size, 100))
        gen_imgs = generator.predict(noise)
        d_loss_real = discriminator.train_on_batch(real_imgs, valid)
        d_loss_fake = discriminator.train_on_batch(gen_imgs, fake)
        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)
        noise = np.random.normal(0, 1, (batch_size, 100))
        g_loss = gan.train_on_batch(noise, valid)
        print(f"Epoch {epoch+1}/{epochs} - D loss: {d_loss[0]} - G loss: {g_loss}")

# CNN Model
def build_cnn_model():
    input_img = layers.Input(shape=(256, 256, 3))
    x = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(input_img)
    x = layers.MaxPooling2D((2, 2), padding='same')(x)
    x = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)
    x = layers.UpSampling2D((2, 2))(x)
    decoded = layers.Conv2D(3, (3, 3), activation='sigmoid', padding='same')(x)
    cnn_model = models.Model(input_img, decoded)
    cnn_model.compile(optimizer='adam', loss='mean_squared_error')
    return cnn_model

# Train CNN Model
def train_model(model, underwater_imgs, reference_imgs):
    # Check the shape of the images. They should be 4-dimensional.
    if underwater_imgs.ndim != 4 or reference_imgs.ndim != 4:
        raise ValueError("Input data should be 4-dimensional")

    # Now train the model with the image arrays
    model.fit(underwater_imgs, reference_imgs, epochs=100, batch_size=1)


# Evaluate model
def evaluate_model(model, underwater_img, reference_img):
    predicted_img = model.predict(np.expand_dims(underwater_img, axis=0))[0]
    predicted_img = np.clip(predicted_img, 0, 1)
    psnr_value = psnr(reference_img, predicted_img, data_range=1)
    ssim_value = ssim(reference_img, predicted_img, multichannel=True)
    return psnr_value, ssim_value

# Display image
def display_image(image, title="Image"):
    plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))
    plt.title(title)
    plt.axis('off')
    plt.show()

# # Function to preprocess input data for GAN and CNN
# def preprocess_images(image):
#     image = cv2.resize(image, (256, 256))
#     image = image.astype(np.float32) / 255.0
#     return image

def load_dataset(underwater_dir, ground_truth_dir):
    underwater_images = []
    ground_truth_images = []

    for filename in os.listdir(underwater_dir):
        if filename.endswith(".jpg"):
            uw_img_path = os.path.join(underwater_dir, filename)
            gt_img_path = os.path.join(ground_truth_dir, filename)

            uw_img = img_to_array(load_img(uw_img_path))
            gt_img = img_to_array(load_img(gt_img_path))

            # Pass both uw_img and gt_img to preprocess_images
            uw_img, gt_img = preprocess_images(uw_img, gt_img)

            underwater_images.append(uw_img)
            ground_truth_images.append(gt_img)

    return np.array(underwater_images), np.array(ground_truth_images)



def preprocess_test_image(image_path):
    image = load_img(image_path, target_size=(256, 256))
    image = img_to_array(image)
    image = image.astype(np.float32) / 255.0  # Normalize the image
    image = np.expand_dims(image, axis=0)  # Add the batch dimension
    return image





# ... [Rest of your code including the training functions] ...

def main():
    # Load and preprocess dataset
    underwater_dir = '/content/drive/MyDrive/A'
    ground_truth_dir = '/content/drive/MyDrive/GTr_A'
    underwater_images, ground_truth_images = load_dataset(underwater_dir, ground_truth_dir)

    # Build and compile GAN
    generator = build_generator()
    discriminator = build_discriminator()
    gan = build_gan(generator, discriminator)

    # Train the GAN
    train_gan(generator, discriminator, gan, underwater_images, epochs=15, batch_size=1)

    # Build and compile CNN model
    cnn_model = build_cnn_model()

    # Split into training and validation sets if needed
    uw_train, uw_val, gt_train, gt_val = train_test_split(underwater_images, ground_truth_images, test_size=0.1)

    # Train the CNN model
    train_model(cnn_model, uw_train, gt_train)

    test_underwater_image_path = '/content/12422.png'
    test_underwater_img = preprocess_test_image(test_underwater_image_path)

    # Predict and display the result
    predicted_img = cnn_model.predict(test_underwater_img)[0]
    display_image(predicted_img, "Enhanced Test Image")

if __name__ == "__main__":
     main()